<aside>
ğŸ¦ˆ 1.  ****Image Classification****

</aside>

## 1. ****Image Classification****

> The problem: semantic gap
: ì˜ë¯¸ìƒì˜ ì°¨ì´ì¸ë°, ì´ëŠ” ìš°ë¦¬ê°€ ì´ë¯¸ì§€ë¥¼ ëˆˆìœ¼ë¡œ ë°›ì•„ë“¤ì´ëŠ” ë°©ì‹ê³¼ëŠ” ë‹¬ë¦¬Â **ì»´í“¨í„°ëŠ” í”½ì…€ ê°’ìœ¼ë¡œ ë°›ì•„ë“¤ì´ê¸° ë•Œë¬¸ì— ìƒê¸°ëŠ” ë¬¸ì œë“¤ì„ ì¼ì»«ëŠ” ê²ƒ**
> 

1)Â **Viewpoint variation**Â :Â ê°ì²´ë¥¼ ë³´ëŠ” ì‹œê°ì— ë”°ë¥¸ ì°¨ì´

2)Â **Illumination**Â :Â ê°ì²´ì— ì˜ì¸ ì¡°ëª…ì—ì„œ ë°œìƒë˜ëŠ” ì°¨ì´

3)Â **Deformation**Â :Â ê°ì²´ì˜ í˜•íƒœ ë³€í™”ì— ë°œìƒë˜ëŠ” ì°¨ì´

4)Â **Occlusion**Â :Â ê°ì²´ê°€ ê°€ë ¤ì ¸ì„œ ë°œìƒë˜ëŠ” ì°¨ì´

5)Â **Background**Â **clutter**Â :Â ê°ì²´ì™€ ë°°ê²½ì˜ íŒ¨í„´ì´ë‚˜ ìƒ‰ì´ êµ¬ë¶„ì´ ì•ˆë˜ë©´ì„œ ë‚˜ì˜¤ëŠ” ì°¨ì´

6)Â **Intraclass variation**Â :Â ê°™ì€ ê°ì²´ë“¤ë„ ì—¬ëŸ¬Â classë¡œ ë‚˜ë‰˜ëŠ” ë¬¸ì œ

### ì´ë¯¸ì§€ ì ‘ê·¼ ë°©ë²•

1. ì´ë¯¸ì§€ ë° ë¼ë²¨ ë°ì´í„° ì„¸íŠ¸ ìˆ˜ì§‘
2. ê¸°ê³„ í•™ìŠµì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ê¸° í›ˆë ¨
3. ìƒˆ ì´ë¯¸ì§€ì— ëŒ€í•œ ë¶„ë¥˜ê¸°ë¥¼ í‰ê°€

## 2. Data - driven approach : Nearest Neighbor & K-NN, Linear clssifier

<aside>
ğŸ¦ˆ **1. Nearest Neighbor
:** ì…ë ¥ë°›ì€ ë°ì´í„°ë¥¼ ì €ì¥í•œ ë‹¤ìŒ ìƒˆë¡œìš´ ì…ë ¥ ë°ì´í„°ê°€ ë“¤ì–´ì˜¤ë©´, ê¸°ì¡´ ë°ì´í„°ì—ì„œ ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ì°¾ì•„ë‚´ëŠ” ë°©ì‹ì´ë‹¤.

</aside>

> CIFAR-10 (10ê°€ì§€ ì¢…ë¥˜ì˜ ë¬¼ì²´ì™€ ë™ë¬¼ì„ ëª¨ì€ ì‚¬ì§„ ë°ì´í„°ë¥¼ ì‚¬ìš©
> 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/851d425a-653f-4e2d-bfaa-a5562b5301ab/Untitled.png)

<aside>
ğŸ¦ˆ 2. ****K-Nearest Neighbor: Distance Metric****
: distance metricì„ ì´ìš©í•´ì„œ ê°€ê¹Œìš´ ì´ì›ƒì„ kê°œë§Œí¼ ì°¾ê³ , ì´ì›ƒ ê°„ì— íˆ¬í‘œë¥¼ í•˜ì—¬ ë“í‘œìˆ˜ê°€ ë§ì´ ì–»ì€ labelë¡œ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•

</aside>

> ****K-Nearest Neighbor ê³¼ì •****
> 
1. Train ê³¼ì • : ëª¨ë“  train dataë¥¼ ê¸°ì–µí•œë‹¤.
2. Predict ê³¼ì • : ì…ë ¥ ë°ì´í„°ë¥¼ train dataì™€ ë¹„êµí•˜ì—¬ ì–´ë–¤ label ê°’ì„ ê°€ì§ˆì§€ ì˜ˆì¸¡í•œë‹¤.

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/8527b657-9b46-4815-b2fb-481e166f63f1/image.png)

ì‹œê°„ë³µì¡ë„: Train O(1), predict O(N)

> **Parameter of K-Nearest Neighbors
1. Distance metric(L1, L2)
2. K**
> 

**1. Distance metric(L1, L2)**

![images_cha-suyeon_post_5d799b42-ff9b-4d2d-9680-bc6a59d29a81_image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/c6ef3f5b-0fa4-4ae6-a92f-dd884d45a114/images_cha-suyeon_post_5d799b42-ff9b-4d2d-9680-bc6a59d29a81_image.png)

![images_cha-suyeon_post_decb8802-bad5-4fba-937e-38476ef02dcf_image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/56f9960f-cd4b-440f-8d81-23494726be4d/images_cha-suyeon_post_decb8802-bad5-4fba-937e-38476ef02dcf_image.png)

- L1 Distanceê°€ ë§ˆë¦„ëª¨ í˜•íƒœë¼ë©´, L2 DistanceëŠ” ì›í˜•ì˜ í˜•íƒœë¡œ, ê¸°í•˜í•™ì ìœ¼ë¡œ êµ¬ì¡° ìì²´ê°€ ë‹¤ë¥´ë‹¤. ë˜í•œ L1 DistanceëŠ” ì¢Œí‘œê³„ë¥¼ íšŒì „ ì‹œ ê±°ë¦¬ê°’ì´ ë‹¬ë¼ì§€ì§€ë§Œ L2 DistanceëŠ” ì¢Œí‘œì˜ ì˜í–¥ì„ ë°›ì§€ ì•ŠëŠ”ë‹¤.

â†’ KNNì„ ì‚¬ìš©í•˜ë ¤ë©´ í•™ìŠµ ì „ ì‚¬ì „ì— Kì™€ ê±°ë¦¬ì²™ë„ì¸ **â€œí•˜ì´í¼ íŒŒë¼ë¯¸í„°â€** ë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.

**2. K closest points**

![images_cha-suyeon_post_9eaede40-0fef-4718-abba-198160e0e3e9_image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/9929cb7e-5c66-4c84-af7a-245bd09df296/images_cha-suyeon_post_9eaede40-0fef-4718-abba-198160e0e3e9_image.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/2a61ff9b-96dd-4f6b-a3d5-c76cdd284f00/Untitled.png)

- kê°€ 1ì¼ ë•ŒëŠ” ê²°ì • ê²½ê³„ê°€ í›ˆë ¨ ë°ì´í„°ì— ê°€ê¹ê²Œ ë”°ë¼ê°„ë‹¤. kê°€ ì¦ê°€í•˜ë©´ ê²°ì • ê²½ê³„ëŠ” ë¶€ë“œëŸ¬ì›Œì§€ë©´ì„œ ë”ìš± ë‹¨ìˆœí•œ ëª¨ë¸ì´ ëœë‹¤.

**í•˜ì´í¼ íŒŒë¼ë¯¸í„°**ë„ 2ê°œë‚˜ ìƒê²¼ê³ , ì´ë¥¼ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆê²Œ ë˜ì—ˆê¸° ë•Œë¬¸ì— NNë³´ë‹¤ëŠ” í›¨ì”¬Â ì„±ëŠ¥ì´ ì¢‹ë‹¤.

## 3.Hyperparameter

> **ìµœì ì˜ Hyperparameter ì°¾ê¸°**
> 
1. ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ë°ì´í„°ì— ë§ê²Œ ë‹¤ì–‘í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ì‹œë„í•´ë³´ê³  ê°€ì¥ ì¢‹ì€ ê°’ì„ ì°¾ëŠ” Trial&Error ë°©ë²•
2. Datasetì„ Train, val, test ë¡œ ë‚˜ëˆ„ì–´ í•œë²ˆë„ ë³´ì§€ ëª»í•œ dataì— ëŒ€í•´ ë¶„ë¥˜ë¥¼ ì˜ í•˜ê²Œ ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„ ì •í•œë‹¤.
3. ë‹¤ìŒê³¼ ê°™ì´ êµì°¨ ê²€ì¦(Cross-Validation)ì„ í•˜ë©´ ë” í™•ì‹¤í•˜ê²Œ ë¶„ë¥˜ë¥¼ ì˜ í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì„ ì°¾ì„ ìˆ˜ ìˆì§€ë§Œ, ë°ì´í„°ê°€ ì‘ì„ ë•ŒëŠ” ê´œì°®ì§€ë§Œ ë°ì´í„°ê°€ ë§ì„ ê²½ìš° ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦°ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/1922a07f-14d8-41ba-8dc1-ea5cfe59c848/Untitled.png)

> **ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œ ì˜ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì´ìœ **
> 
1. testë¥¼ í•˜ëŠ”ë° ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.
2. ì´ë¯¸ì§€ ë°ì´í„°ì— Distance Metric(L1, L2)ëŠ” ë§¤ìš° ë¹„í•©ë¦¬ì ì¸ ë°©ì‹ì´ë‹¤.
    - ë²¡í„° ê°„ì˜ ê±°ë¦¬ ì¸¡ì • ê´€ë ¨ í•¨ìˆ˜(L1,L2)ë“¤ì€ ì´ë¯¸ì§€ë“¤ ê°„ì˜ â€˜ì‹œê°ì  ìœ ì‚¬ì„±â€™ì„ ì¸¡ì •í•˜ëŠ” ì²™ë„ë¡œ ì ì ˆí•˜ì§€ ì•Šë‹¤.
    - ë‹¤ìŒ ì´ë¯¸ì§€ë“¤ ê°„ L2 distanceë¥¼ ì¸¡ì •í–ˆì„ ë•Œ ëª¨ë‘ ê°™ë‹¤.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/aab0547b-1ae0-46f2-b448-7ba91d94cf3a/Untitled.png)

## 4.Linear Classification

<aside>
ğŸ¦ˆ Linear Classification
: Neural Networkë¥¼ êµ¬ì„±í•˜ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ ìš”ì†Œì´ë‹¤. NNì€ ì—¬ëŸ¬ ê°œì˜ ë‹¤ì–‘í•œ ì¸µë“¤ì„ ë§ˆì¹˜ ë ˆê³ ë¸”ëŸ­ì²˜ëŸ¼ ìŒ“ì•„ í•˜ë‚˜ì˜ ê±°ëŒ€í•œ íƒ€ì›Œë¥¼ ì§“ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.

</aside>

> ****Linear Classification ê³¼ì •****
> 

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/c4b9f736-1fc9-4cad-a78a-32cebcb5b2d7/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/3ee9d6bc-ae20-45a9-aa9a-c86fb12a1fdf/Untitled.png)

X : input image

W : ê°€ì¤‘ì¹˜(Weight)

b : ë°”ì´ì–´ìŠ¤, ê³±ì„ ëë‚´ê³  ë”í•˜ëŠ” ì—­í• ë¡œ ë°ì´í„°ì— ë¬´ê´€í•˜ê²Œ íŠ¹ì • í´ë˜ìŠ¤ì— ìš°ì„ ê¶Œì„ ë¶€ì—¬í•œë‹¤.(scaling offset) â†’ ë§Œì•½, ë°ì´í„°ì…‹ì— ê³ ì–‘ì´ë§Œ ì—„ì²­ ë§ê³  ê°œëŠ” ì—„ì²­ ì ìœ¼ë©´ ë‹¹ì—°íˆ ì–´ë–¤ ì‚¬ì§„ì„ ë´¤ì„ ë•Œ ê·¸ê²Œ ê³ ì–‘ì´ì¼ í™•ë¥ ì´ ë” í¬ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ bias ê°’ì„ ê³ ì–‘ì´ì— ë” í¬ê²Œ ë¶€ê³¼í•´ ì£¼ì–´, 'ê³ ì–‘ì´' ì ìˆ˜ì— ë³´ë„ˆìŠ¤ë¥¼ ì£¼ëŠ” ê²ƒì´ë‹¤.

- f(x,W) = Wx + bëŠ” Linear Classificationì´ë‹¤.
- ì´ë¯¸ì§€ ë°ì´í„°ì™€ ê°€ì¤‘ì¹˜ ê°’ì„ ë”í•´ ê° 10ê°œì˜ classì— ëŒ€í•œ scoreë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.
- trainì„ ì‹œí‚¤ë©° Wì— ì ì ˆí•œ ê°€ì¤‘ì¹˜ ê°’ì„ ëª¨ì•„ì¤€ë‹¤.
- ì´ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ì´ìš©í•´ ë‚®ì€ ì„±ëŠ¥ì˜ ê¸°ê¸°ì—ì„œë„ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ predictë¥¼ ë¹ ë¥´ê²Œ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/c4932e9c-1c36-46c0-a0ab-e4db40710d34/Untitled.png)

> ****Linear Classification í•œê³„****
> 
- **ê³µê°„ ì •ë³´ë¥¼ í™œìš©í•  ìˆ˜ ì—†ë‹¤ëŠ” ë‹¨ì ì„ ê·¹ë³µí•˜ì§€ ëª»í•œ ê²ƒì…ë‹ˆë‹¤.**

![img1.daumcdn.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/9dfb4a02-093a-4967-b0d0-621896377d7e/img1.daumcdn.png)

ì•„ì§ë„ í”½ì…€ê°’ë“¤ì˜ ê³„ì‚°ë§Œìœ¼ë¡œ ì˜ì¡´í•˜ì—¬ ì»¬ëŸ¬ì—ë§Œ ë„ˆë¬´ ë¯¼ê°í•œ ëª¨ë¸ì´ë‹¤.

ìœ„ ìŠ¬ë¼ì´ë“œì— dogë¥¼ ë³´ë©´ ê°ˆìƒ‰ì´ì§€ë§Œ ê°œì˜ í˜•íƒœëŠ” ì˜ ë³´ì´ì§€ ì•ŠëŠ”ë‹¤.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/29798440-0cd5-4626-93b6-1db5c884872e/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/cdbf9ab8-5ffb-45ca-85d8-0c7afc66e645/Untitled.png)

ì´ë¯¸ì§€ë¥¼ Score functionì„ ì´ìš©í•˜ì—¬ Scoreë¡œ ë§Œë“¤ì—ˆê³ , ì•ìœ¼ë¡œ í•´ì•¼ë  ê²ƒì€ loss functionì„ ì´ìš©í•˜ì—¬ Scoreë¥¼ lossë¡œ ë§Œë“¤ì–´ì•¼ í•œë‹¤.

â†’ loss function: ì†ì‹¤ í•¨ìˆ˜ëŠ” ë°ì´í„°ë¥¼ í† ëŒ€ë¡œ ì‚°ì¶œí•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ê³¼ì˜ ì°¨ì´ë¥¼ í‘œí˜„í•˜ëŠ” ì§€í‘œ

## 2. Loss fn, Optimization

<aside>
ğŸ¦ˆ **1. Multiclass SVM loss**

</aside>

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/869ee37b-8f15-4070-b79c-2eb883931db0/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/3bd01b5f-2453-422a-afff-0be53a5abd6e/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/a139627f-c16f-470c-8e9c-e40f17f344ac/Untitled.png)

x = image single column vector

y = labelì„ ë‚˜íƒ€ë‚´ëŠ” integer ê°’

W = parameter

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/8157f647-cf39-49aa-a19a-c844c4b4aee0/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/25667aa5-0d4e-486f-a482-d51989a3b6fa/Untitled.png)

Data Loss : í•™ìŠµìš© ë°ì´í„°ë“¤ì— ìµœëŒ€í•œ ìµœì í™”ë˜ë„ë¡ í•¨

Regularization Loss : í…ŒìŠ¤íŠ¸ ë°ì´í„°ë“¤ì— ìµœëŒ€í•œ ìµœì í™”ë˜ë„ë¡ 

<aside>
ğŸ¦ˆ 2. Softmax (Multinomial Logistic Regression)- Cross entropy loss

</aside>

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/e7a2d87b-9940-4707-a8e8-20b0b5681598/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/11fefa30-47de-418d-9b64-6d3deb8153bb/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/e1e15616-138a-4025-aba7-594c67e7b0c7/Untitled.png)

<aside>
ğŸ¦ˆ 3. **Optimization
:** Lossë¥¼ minimizeí•˜ëŠ” weightë¥¼ ì°¾ì•„ê°€ëŠ” ê³¼ì •

</aside>

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/878c0d64-8be4-4d3f-8236-8ea246dfa01a/Untitled.png)

â†’ Wê°’ì„ ë°”ê¿”ê°€ë©´ì„œ, ìµœì ì˜ lossê°’ì„ ì°¾ëŠ” ê²ƒâ†’ bad solutin

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/3a466b3d-14e3-4ea0-a302-efa354978522/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/b40d54c3-e5f9-4a7a-b5d1-69215fbec041/Untitled.png)

0.0001ì´ë¼ëŠ”, ì•„ì£¼ ì ì€ ìˆ˜ë¥¼ Wì˜ ì²« ë²ˆì§¸ ì›ì†Œì— ë”í•´ë³´ë‹ˆ, Lossê°€ ì¤„ì—ˆê³  'ë¯¸ë¶„'ì„ í•´ë³´ë‹ˆ, ê¸°ìš¸ê¸°ê°€Â -2.5ê°€ ë‚˜ì™”ë‹¤

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/1ec44f2b-8148-4573-9c06-aa7a1c7b9d9d/Untitled.png)

lossê°€ ì»¤ì¡Œê³ , ë¯¸ë¶„ì„ í•´ë³´ë‹ˆ ê¸°ìš¸ê¸° ê°’ì´ ì–‘ìˆ˜ì¸ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/71e43042-6b5e-4708-a658-ef7aa854e132/Untitled.png)

â†’ ë‹¨ì : ê·¼ì‚¬ì¹˜, í‰ê°€ ì†ë„ê°€ ëŠë¦¼

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/5c3d44fa-5a0f-4545-bf1b-92e94f589eba/Untitled.png)

numerical: f(x+h)-f(x) / hë¥¼ í•œ ê²ƒ, ì“°ê¸° ì‰½ë‹¤, ê·¼ì‚¬ì¹˜ì´ê³  ëŠë¦¬ë‹¤

analytic: ë¯¸ë¶„ ê³µì‹ìœ¼ë¡œÂ ë‚˜ì˜¨Â ê²ƒ, ì •í™•í•˜ê³  ë¹ ë¥´ë‹¤, ì—ëŸ¬ê°€ ë§ë‹¤

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/ce4b5829-4a0d-4045-bd9f-8c64c88b2738/Untitled.png)

step_size = learning rate

gradient ê°’ë§Œí¼ learning rateë¥¼ ê°ì†Œì‹œì¼œì•¼ í•˜ê¸° ë•Œë¬¸ì—(-)ë¥¼ ê³±í•¨

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/1f51bf11-dc47-4efa-9d1d-612b472877a0/Untitled.png)

- training setì˜ ì¼ë¶€ë§Œì„ í™œìš©í•˜ì—¬ gradientë¥¼ ê³„ì‚°í•˜ê³  parameterë¥¼ ì—…ë°ì´íŠ¸

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/ac90e89d-d931-47d8-87d8-f44362b72eeb/27e165eb-1d35-4338-a6d6-8df6d9a346a4/Untitled.png)

ë‹¨ê¸°ì ìœ¼ë¡œ ë…¸ì´ì¦ˆê°€ ë§ì§€ë§Œ ì¥ê¸°ì ìœ¼ë¡œ lossê°€ ê°ì†Œí•¨

## Summary

!https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F7b5ea163-dd3c-4ed9-a5a9-74e536656117%2Fimage.png

(*x*,*y*)ë¼ëŠ” ê³ ì •ëœ ë°ì´í„° ìŒì´ ìˆì„ ë•Œ, ì²˜ìŒì— ë¬´ì‘ìœ„ë¡œ ë½‘ì€ parameter ê°’ìœ¼ë¡œ ë°”ë€Œì–´ ë‚˜ê°„ë‹¤.

ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™í•˜ë©´ì„œ score functionì€ ê° classì˜ scoreë¥¼ ê³„ì‚°í•˜ê³ , ê·¸ ê°’ì´ f ë²¡í„°ì— ì €ì¥ëœë‹¤.

loss functionì€Â `data loss`ì™€Â `regularization loss`ë¡œ ë‚˜ë‰˜ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. Gradient descent ê³¼ì •ì—ì„œ parameterë¡œ ë¯¸ë¶„í•œ gradientë¥¼ ê³„ì‚°í•˜ê³  ì´ë¥¼ ì´ìš©í•´ parameterë¥¼ ì—…ë°ì´íŠ¸í•œë‹¤.

- loss functionì€ ì‚° ê¼­ëŒ€ê¸°ì—ì„œ ì•„ë˜ë¡œ ë‚´ë ¤ê°€ëŠ” ê²ƒìœ¼ë¡œ ìµœì í™” ê³¼ì •ì„ ì„¤ëª…í–ˆë‹¤. íŠ¹íˆ SVM loss ì˜ ê²½ìš°

!https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F6041f982-88e1-48ae-ba30-f3744fc13c14%2Fimage.png

loss functionì€ ì„ í˜•ì˜ ëª¨ì–‘ìœ¼ë¡œ ê°€ì¥ ì¢‹ì€ parameter ê°’ì¸ íŒŒë€ìƒ‰ìœ¼ë¡œ ì´ë™í•´ì•¼ í•˜ëŠ” ê²½ìš°ì˜€ë‹¤.

- loss functionì„ optimizeí•œë‹¤ëŠ” ê²ƒì€ ë¬´ì‘ìœ„ë¡œ ì‹œì‘í•´ì„œ ë°˜ë³µí•˜ë©° ë” ë‚˜ì€ìª½ìœ¼ë¡œ ì´ë™í•œë‹¤ëŠ” í•µì‹¬ ê°œë…ì—ì„œ ì‹œì‘ë˜ì—ˆë‹¤.
- gradient(ê¸°ìš¸ê¸°)ëŠ” ê·¸ í•¨ìˆ˜ê°’ì´ ê°ì†Œí•˜ëŠ” ê°€ì¥ ë¹ ë¥¸ ë°©í–¥ì´ë‹¤. ì´ê²ƒì„ ìœ í•œ ì°¨ë¶„(finite difference, ì¦‰ ë¯¸ë¶„í•  ë•Œ hì˜ ê°’ì´ ìœ í•œí•˜ë‹¤ëŠ” ì˜ë¯¸)ë¥¼ ì´ìš©í•˜ì—¬ ë‹¨ìˆœ ë¬´ì‹í•˜ê²Œ ìˆ˜ì¹˜ì ìœ¼ë¡œ ì–´ë¦¼ì¡ì•„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ë„ ì‚´í´ ë³´ì•˜ë‹¤.
    - ê°•ì˜ì—ì„œëŠ” ì´ëŸ¬í•œ ìˆ˜ì¹˜ì  ë¯¸ë¶„ë³´ë‹¤ í•´ì„ì  ë¯¸ë¶„ì´ ë” ì¢‹ë‹¤ê³  ì–¸ê¸‰í•˜ì˜€ë‹¤.
- parameterÂ *w*ë¥¼ ì—…ë°ì´íŠ¸í•  ë•Œ, í•œ ë²ˆì— ì–¼ë§ˆë‚˜ ì›€ì§ì—¬ì•¼ í•˜ëŠ”ì§€ë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì´Â `step size(learning rate, lr)`ì´ì—ˆë‹¤. í•™ìŠµ ì†ë„ì— ì˜í–¥ì„ ì£¼ëŠ” hyper parameterì´ë‹¤.
    - ì´ ê°’ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë„ˆë¬´ ëŠë ¤ì§€ê³ , ë„ˆë¬´ ë†’ìœ¼ë©´ ë¹¨ë¼ì§€ì§€ë§Œ ìœ„í—˜í•œ ì ì´ ìˆë‹¤.
- ìˆ˜ì¹˜ì  ë¯¸ë¶„ê³¼ í•´ì„ì  ë¯¸ë¶„ì˜ ë°©ë²•
    - ìˆ˜ì¹˜ì  gradinet: ë‹¨ìˆœí•˜ì§€ë§Œ ê·¼ì‚¬ê°’ì´ê³  ë¹„íš¨ìœ¨ì ì„
    - í•´ì„ì  gradient: ì •í™•í•˜ê³  ë¹ ë¥´ì§€ë§Œ ì†ìœ¼ë¡œ ê³„ì‚°í•´ì„œ ì‹¤ìˆ˜í•  ìˆ˜ ìˆìŒ
    - ì‹¤ì œ ì‘ìš©ì—ì„œëŠ” í•´ì„ì ì¸ gradientì„ ì”ë‹ˆë‹¤. ë˜í•œ, ë‘˜ ë‹¤ êµ¬í•œ ë‹¤ìŒ ë¹„êµí•´ë³´ê³ , í‹€ë¦° ê²½ìš° ê³ ì¹˜ëŠ” gradient check ê³¼ì •ì„ ê°–ë‹¤.
- ë°˜ë³µì ìœ¼ë¡œ ë£¨í”„(loop)ë¥¼ ëŒë ¤ì„œ gradientë¥¼ ê³„ì‚°í•˜ê³  parameterë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” Gradient Descent ì•Œê³ ë¦¬ì¦˜ì„ ì†Œê°œí–ˆë‹¤.
